{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'images', 'target', 'DESCR'])\n",
      ".. _olivetti_faces_dataset:\n",
      "\n",
      "The Olivetti faces dataset\n",
      "--------------------------\n",
      "\n",
      "`This dataset contains a set of face images`_ taken between April 1992 and \n",
      "April 1994 at AT&T Laboratories Cambridge. The\n",
      ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
      "fetching / caching function that downloads the data\n",
      "archive from AT&T.\n",
      "\n",
      ".. _This dataset contains a set of face images: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
      "\n",
      "As described on the original website:\n",
      "\n",
      "    There are ten different images of each of 40 distinct subjects. For some\n",
      "    subjects, the images were taken at different times, varying the lighting,\n",
      "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "    details (glasses / no glasses). All the images were taken against a dark\n",
      "    homogeneous background with the subjects in an upright, frontal position \n",
      "    (with tolerance for some side movement).\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   =====================\n",
      "    Classes                                40\n",
      "    Samples total                         400\n",
      "    Dimensionality                       4096\n",
      "    Features            real, between 0 and 1\n",
      "    =================   =====================\n",
      "\n",
      "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
      "integers; the loader will convert these to floating point values on the \n",
      "interval [0, 1], which are easier to work with for many algorithms.\n",
      "\n",
      "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
      "identity of the person pictured; however, with only 10 examples per class, this\n",
      "relatively small dataset is more interesting from an unsupervised or\n",
      "semi-supervised perspective.\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the version available here\n",
      "consists of 64x64 images.\n",
      "\n",
      "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = datasets.fetch_olivetti_faces()\n",
    "print(data.keys())\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.739669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.714876</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.173554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
       "1  0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
       "2  0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
       "3  0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
       "4  0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
       "\n",
       "       7         8         9     ...      4086      4087      4088      4089  \\\n",
       "0  0.677686  0.690083  0.685950  ...  0.665289  0.669421  0.652893  0.661157   \n",
       "1  0.702479  0.710744  0.702479  ...  0.136364  0.157025  0.136364  0.148760   \n",
       "2  0.685950  0.702479  0.698347  ...  0.074380  0.132231  0.181818  0.136364   \n",
       "3  0.404959  0.483471  0.516529  ...  0.652893  0.636364  0.657025  0.685950   \n",
       "4  0.714876  0.723140  0.731405  ...  0.190083  0.161157  0.177686  0.173554   \n",
       "\n",
       "       4090      4091      4092      4093      4094      4095  \n",
       "0  0.475207  0.132231  0.148760  0.152893  0.161157  0.157025  \n",
       "1  0.152893  0.152893  0.152893  0.152893  0.152893  0.152893  \n",
       "2  0.128099  0.148760  0.144628  0.140496  0.148760  0.152893  \n",
       "3  0.727273  0.743802  0.764463  0.752066  0.752066  0.739669  \n",
       "4  0.177686  0.177686  0.177686  0.177686  0.173554  0.173554  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camdata = pd.DataFrame(data[\"data\"])\n",
    "camdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.714876</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.351240</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334711</td>\n",
       "      <td>0.289256</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.458678</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.223140</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.202479</td>\n",
       "      <td>0.276859</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392562</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>0.524793</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.603306</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>0.462810</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.252066</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.359504</td>\n",
       "      <td>0.355372</td>\n",
       "      <td>0.384298</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
       "1    0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
       "2    0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
       "3    0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
       "4    0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  0.400826  0.495868  0.570248  0.632231  0.648760  0.640496  0.661157   \n",
       "396  0.367769  0.367769  0.351240  0.301653  0.247934  0.247934  0.367769   \n",
       "397  0.500000  0.533058  0.607438  0.628099  0.657025  0.632231  0.657025   \n",
       "398  0.214876  0.219008  0.219008  0.223140  0.210744  0.202479  0.276859   \n",
       "399  0.516529  0.462810  0.280992  0.252066  0.247934  0.367769  0.574380   \n",
       "\n",
       "            7         8         9  ...      4087      4088      4089  \\\n",
       "0    0.677686  0.690083  0.685950  ...  0.669421  0.652893  0.661157   \n",
       "1    0.702479  0.710744  0.702479  ...  0.157025  0.136364  0.148760   \n",
       "2    0.685950  0.702479  0.698347  ...  0.132231  0.181818  0.136364   \n",
       "3    0.404959  0.483471  0.516529  ...  0.636364  0.657025  0.685950   \n",
       "4    0.714876  0.723140  0.731405  ...  0.161157  0.177686  0.173554   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395  0.636364  0.665289  0.698347  ...  0.396694  0.264463  0.099174   \n",
       "396  0.512397  0.574380  0.628099  ...  0.334711  0.289256  0.285124   \n",
       "397  0.669421  0.673554  0.702479  ...  0.148760  0.152893  0.161157   \n",
       "398  0.400826  0.487603  0.549587  ...  0.392562  0.367769  0.409091   \n",
       "399  0.615702  0.661157  0.615702  ...  0.264463  0.293388  0.301653   \n",
       "\n",
       "         4090      4091      4092      4093      4094      4095   y  \n",
       "0    0.475207  0.132231  0.148760  0.152893  0.161157  0.157025   0  \n",
       "1    0.152893  0.152893  0.152893  0.152893  0.152893  0.152893   0  \n",
       "2    0.128099  0.148760  0.144628  0.140496  0.148760  0.152893   0  \n",
       "3    0.727273  0.743802  0.764463  0.752066  0.752066  0.739669   0  \n",
       "4    0.177686  0.177686  0.177686  0.177686  0.173554  0.173554   0  \n",
       "..        ...       ...       ...       ...       ...       ...  ..  \n",
       "395  0.181818  0.243802  0.247934  0.161157  0.157025  0.136364  39  \n",
       "396  0.338843  0.404959  0.458678  0.487603  0.512397  0.549587  39  \n",
       "397  0.161157  0.173554  0.157025  0.177686  0.148760  0.190083  39  \n",
       "398  0.479339  0.524793  0.545455  0.574380  0.590909  0.603306  39  \n",
       "399  0.293388  0.322314  0.322314  0.359504  0.355372  0.384298  39  \n",
       "\n",
       "[400 rows x 4097 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camdata[\"y\"] = data[\"target\"]\n",
    "camdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(camdata, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = np.arange(0, 4096)\n",
    "X = train[cols].values\n",
    "y = train.y.values\n",
    "\n",
    "X_test = test[cols].values\n",
    "y_test = test.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python_2021\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Python_2021\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X,y)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "\n",
    "model.fit(X,y)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- What are the features?\n",
    "\n",
    "The features are the real values between 0 and 1 and amounts to total 4096 points."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- What was it your classifier was trying to classify? (Hint: You'll need to read the description of the data--this constitutes the classification \"task\"; i.e., the mapping from features in X to the classification labels in y)?\n",
    "\n",
    "The dataset is trying to classify the feature points to construct a picture."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- What is the baseline for this dataset? (Hint: what is the most common type that could be classified?)\n",
    "\n",
    "10% (uniform: generates predictions uniformly at random.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- How well did your three classifiers do above the baseline.\n",
    " \n",
    "The logicstic regression showed the best performance and the Random Forest also performed extremely well. However, the Decision tree classifier produced relatively low accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Read a little bit about each classifier. Why do you think one classifier did better than another classifier?\n",
    "\n",
    "Among the three classifiers, Logistic regression outperformed all. This classifier works well with large number of samples. Ob the other hand, Decision tree performed poorly. Decision tree works on based on layer spiltting method. At each layer, we attempt to divide data into two or more groups so that all observations in the same group are most similar to one another (homogeneity) and the groups are notably dissimilar from one another (heterogeneity). Decision tree has certain drawbacks and I belive the above model experienced this. They very easily overfit. As the depth of the tree rises, so does overfitting. Decision tree is also inherently unstable. slightl change in sub-sample causes the structure of the tree to alter significantly.\n",
    "\n",
    "By using Random forest, the score can be improved as it can fix this issue by ensembling. As tree depth grows, random forests outperform single decision trees in resisting overfitting. They also tend to be less unstable than decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link Prediction (IMDb Movie Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What are the input features?\n",
    "\n",
    "- Review text.\n",
    "\n",
    "What are the class labels?\n",
    "\n",
    "- positive sentiment or negative sentiment.\n",
    "\n",
    "How is the data represented?\n",
    "\n",
    "- The dataset has 50000 rows 2 columns where the review columns holds the review text and sentiment column says the corresponding sentiment that is expressed throught the review text.\n",
    "\n",
    "Do you think any of the three classification approaches you used for the Olivettie Faces above would work for this task?\n",
    "\n",
    "- I think Logistic regression would work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Generation(CNN/Daily Mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What are the input features?\n",
    "\n",
    "- Article and highlights.\n",
    "\n",
    "What are the class labels?\n",
    "\n",
    "- Abstractive summarization(responding to the fill-in-the-blank question).\n",
    "\n",
    "How is the data represented?\n",
    "\n",
    "- For each occurrence, there is a string for the article, a string for the highlights, and a string for the id.\n",
    "\n",
    "Do you think any of the three classification approaches you used for the Olivettie Faces above would work for this task?\n",
    "\n",
    "- Although I believe that the classification methods I adopted for Olivettie Faces are not that suitable in this connection, I would go with Random Forest if I am to use any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
